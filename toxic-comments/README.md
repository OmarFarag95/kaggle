# Kaggle Toxic Comment Classification Challenge

- This still a work in progress _trying to achieve better score on test set_
- [Link to Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)

## Dataset Brief Description

- The dataset contains comments categorized as **Toxic comments** and **Non-Toxic (clean) comments**. 
- The **Toxic comments** are further categorized into **toxic**, **sever toxic**, **obscene**, **insult**, **threat** and **identity hate**.
- Number of **Toxic comments**: 16225
- Number of **Non-Toxic (Clean) comments**: 143346

## Visualizations from the Dataset

- Number of comments per **Toxic comments** subcategories.

![plot](https://github.com/OmarFarag95/kaggle/blob/main/toxic-comments/img/toxic_comments_categorization.png)

- Frequent words in **Toxic comments**

![plot](https://github.com/OmarFarag95/kaggle/blob/main/toxic-comments/img/toxic_freq_words.png)

- Frequent words in **Non-Toxic (Clean) comments**

![plot](https://github.com/OmarFarag95/kaggle/blob/main/toxic-comments/img/nontoxic_freq_words.png)

- Average Number of words per comment type

![plot](https://github.com/OmarFarag95/kaggle/blob/main/toxic-comments/img/average_no_of_words.png)
